{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97533b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from utils.document_classification import *\n",
    "from langchain.schema import Document\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eff9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_dir):\n",
    "    documents = []\n",
    "\n",
    "    root_dir = Path(root_dir)\n",
    "\n",
    "    for label_dir in root_dir.iterdir():\n",
    "        if not label_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        label = label_dir.name\n",
    "        \n",
    "        # load the file and get the document object\n",
    "        for file_path in label_dir.rglob(\"*\"):\n",
    "            if file_path.suffix.lower() not in SUPPORTED_EXTENSIONS:\n",
    "                continue\n",
    "            docs = load_file(str(file_path))\n",
    "\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"label\"] = label\n",
    "                doc.metadata[\"source\"] = str(file_path)\n",
    "                documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2ad725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file due to load error: data/Research Paper/13_Understanding LSTM Networks -- colahs blog.pdf (Odd-length string)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united states securities and exchange commissi...</td>\n",
       "      <td>SEC Filing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qualcomm incorporated form 10-q for the quarte...</td>\n",
       "      <td>SEC Filing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk factors summary:our business is subject t...</td>\n",
       "      <td>SEC Filing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risks related to regulatory and legal challeng...</td>\n",
       "      <td>SEC Filing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>part i.financial information item 1.condensed ...</td>\n",
       "      <td>SEC Filing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        page_content       label\n",
       "0  united states securities and exchange commissi...  SEC Filing\n",
       "1  qualcomm incorporated form 10-q for the quarte...  SEC Filing\n",
       "2  risk factors summary:our business is subject t...  SEC Filing\n",
       "3  risks related to regulatory and legal challeng...  SEC Filing\n",
       "4  part i.financial information item 1.condensed ...  SEC Filing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = load_data(\"data\")\n",
    "data_df = pd.DataFrame(\n",
    "    {\n",
    "        \"page_content\": [remove_redundant_space(format_string(process_single_quotes(doc.page_content))) for doc in loaded_data],\n",
    "        \"label\": [doc.metadata[\"label\"] for doc in loaded_data],\n",
    "    }\n",
    ")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66680627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Earnings Call Transcript    1185\n",
       "News Article                2926\n",
       "Press Release                 24\n",
       "Research Paper              1265\n",
       "SEC Filing                  4091\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db99aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (7592, 27612)\n",
      "Testing data shape: (1899, 27612)\n",
      "Training Accuracy: 0.9934\n",
      "Testing Accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data_df[\"page_content\"], \n",
    "    data_df[\"label\"], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df = 5, max_df = .80, norm = 'l2', sublinear_tf = True, stop_words='english')\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(\"Training data shape:\", train_x_vectors.shape)\n",
    "print(\"Testing data shape:\", test_x_vectors.shape)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(C = 0.5, penalty = 'l2', solver='liblinear')\n",
    "model.fit(train_x_vectors, train_y)\n",
    "\n",
    "# Evaluate model performance\n",
    "train_accuracy = model.score(train_x_vectors, train_y)\n",
    "test_accuracy = model.score(test_x_vectors, test_y)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258630a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced error rate (BER) calculation\n",
    "def balanced_error_rate(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_errors = []\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        tn = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - cm[i, i]\n",
    "        tp = cm[i, i]\n",
    "\n",
    "        if (tp + fn) == 0:\n",
    "            fnr = 0\n",
    "        else:\n",
    "            fnr = fn / (tp + fn)\n",
    "\n",
    "        if (tn + fp) == 0:\n",
    "            fpr = 0\n",
    "        else:\n",
    "            fpr = fp / (tn + fp)\n",
    "\n",
    "        per_class_errors.append((fnr + fpr) / 2)\n",
    "\n",
    "    ber = np.mean(per_class_errors)\n",
    "    return ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78dbc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Error Rate (BER): 0.1062\n"
     ]
    }
   ],
   "source": [
    "balanced_error_rate = balanced_error_rate(test_y, model.predict(test_x_vectors))\n",
    "print(f\"Balanced Error Rate (BER): {balanced_error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ffd233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TFIDF_Vectorizer.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model and vectorizer\n",
    "import joblib\n",
    "joblib.dump(model, \"Document_Classifier.joblib\")\n",
    "joblib.dump(vectorizer, \"TFIDF_Vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fece4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-foundry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
